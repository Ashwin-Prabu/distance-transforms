{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4YEcDwgizKu"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FUeJ-AFNicKD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.ndimage import distance_transform_edt as distance\n",
        "from scipy.ndimage import _nd_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnZ93kizphQ7",
        "outputId": "bd771e74-9e6f-49e9-f9e4-08c5dc158463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-lqe75di1os"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "txD1IQYMEd1u"
      },
      "outputs": [],
      "source": [
        "def dice_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target * target)\n",
        "    z_sum = torch.sum(score * score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hd_loss_2D(seg_soft, gt, seg_dtm, gt_dtm):\n",
        "    \"\"\"\n",
        "    compute huasdorff distance loss for binary segmentation\n",
        "    input: seg_soft: softmax results,  shape=(b,2,x,y,z)\n",
        "           gt: ground truth, shape=(b,x,y,z)\n",
        "           seg_dtm: segmentation distance transform map; shape=(b,2,x,y,z)\n",
        "           gt_dtm: ground truth distance transform map; shape=(b,2,x,y,z)\n",
        "    output: boundary_loss; sclar\n",
        "    \"\"\"\n",
        "\n",
        "    delta_s = (seg_soft - gt) ** 2\n",
        "    s_dtm = seg_dtm ** 2\n",
        "    g_dtm = gt_dtm ** 2\n",
        "    dtm = s_dtm + g_dtm\n",
        "    multipled = torch.einsum('xy, xy->xy', delta_s, dtm)\n",
        "    hd_loss = multipled.mean()\n",
        "\n",
        "    return hd_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VeuTs25pEgnK"
      },
      "outputs": [],
      "source": [
        "def hd_loss_3D(seg_soft, gt, seg_dtm, gt_dtm):\n",
        "    \"\"\"\n",
        "    compute huasdorff distance loss for binary segmentation\n",
        "    input: seg_soft: softmax results,  shape=(b,2,x,y,z)\n",
        "           gt: ground truth, shape=(b,x,y,z)\n",
        "           seg_dtm: segmentation distance transform map; shape=(b,2,x,y,z)\n",
        "           gt_dtm: ground truth distance transform map; shape=(b,2,x,y,z)\n",
        "    output: boundary_loss; sclar\n",
        "    \"\"\"\n",
        "\n",
        "    delta_s = (seg_soft - gt) ** 2\n",
        "    s_dtm = seg_dtm ** 2\n",
        "    g_dtm = gt_dtm ** 2\n",
        "    dtm = s_dtm + g_dtm\n",
        "    multipled = torch.einsum('xyz, xyz->xyz', delta_s, dtm)\n",
        "    hd_loss = multipled.mean()\n",
        "\n",
        "    return hd_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnODxVk4-ft0"
      },
      "source": [
        "# Benchmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_range = range(1, 510, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RoxFJiEd-o21"
      },
      "outputs": [],
      "source": [
        "sizes_2D = []\n",
        "sizes_3D = []\n",
        "\n",
        "hd_mean_2D = []\n",
        "hd_std_2D = []\n",
        "\t\n",
        "dice_mean_2D = []\n",
        "dice_std_2D = []\n",
        "\t\n",
        "hd_mean_3D = []\n",
        "hd_std_3D = []\n",
        "\t\n",
        "dice_mean_3D = []\n",
        "dice_std_3D = []\n",
        "\n",
        "hd_times = []\n",
        "dice_times = []\n",
        "hd_3D_times = []\n",
        "dice_3D_times = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_cases_2D = []\n",
        "\n",
        "for n in num_range:\n",
        "    _size = n**2\n",
        "    sizes_2D.append(_size)\n",
        "    test_cases_2D.append(torch.randint(0,2,(n,n)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_cases_3D = []\n",
        "\n",
        "for n in num_range:\n",
        "    _size = n**3\n",
        "    sizes_3D.append(_size)\n",
        "    test_cases_3D.append(torch.randint(0,2,(n,n,n)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zae9TGZDvHbY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HD Size:  1\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m array \u001b[39min\u001b[39;00m test_cases_2D:\n\u001b[0;32m      3\u001b[0m   \u001b[39m# HD GPU\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHD Size: \u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39mlen\u001b[39m(array))\n\u001b[1;32m----> 5\u001b[0m   tfm1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(distance(array))\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m      6\u001b[0m   n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(array)\n\u001b[0;32m      7\u001b[0m   g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,(n,n))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\cuda\\__init__.py:208\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    207\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "#2D\n",
        "for array in test_cases_2D:\n",
        "  # HD GPU\n",
        "  print(\"HD Size: \",  len(array))\n",
        "  tfm1 = torch.from_numpy(distance(array)).cuda()\n",
        "  n = len(array)\n",
        "  g = torch.randint(0,2,(n,n))\n",
        "  tfm2 = torch.from_numpy(distance(g)).cuda()\n",
        "  g1 = g.cuda()\n",
        "  array1 = array.cuda()\n",
        "  a = []\n",
        "  for j in range(1000): #Evaluations\n",
        "    times1 = time.time_ns()\n",
        "    hd = hd_loss_2D(array1, g1, tfm1, tfm2)\n",
        "    times2 = time.time_ns()\n",
        "    a.append(times2-times1)\n",
        "    if sum(a) > (15*60*(10**9)):\n",
        "      break\n",
        "  hd_times.append(a)\n",
        "\n",
        "for array in test_cases_2D:\n",
        "  # Dice GPU\n",
        "  print(\"Dice Size: \",  len(array))\n",
        "  b = []\n",
        "  n = len(array)\n",
        "  g = torch.randint(0,2,(n,n)).cuda()\n",
        "  array1 = array.cuda()\n",
        "  for j in range(1000): #Evaluations\n",
        "    times1 = time.time_ns()\n",
        "    dice = dice_loss(array1, g)\n",
        "    times2 = time.time_ns()\n",
        "    b.append(times2-times1)\n",
        "    if sum(b) > (20*60*(10**9)):\n",
        "      break\n",
        "  dice_times.append(b)\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HD Size:  1\n",
            "HD Size:  11\n",
            "HD Size:  21\n",
            "HD Size:  31\n",
            "HD Size:  41\n",
            "HD Size:  51\n",
            "HD Size:  61\n",
            "HD Size:  71\n",
            "HD Size:  81\n",
            "HD Size:  91\n",
            "HD Size:  101\n",
            "HD Size:  111\n",
            "HD Size:  121\n",
            "HD Size:  131\n",
            "HD Size:  141\n",
            "HD Size:  151\n",
            "HD Size:  161\n",
            "HD Size:  171\n",
            "HD Size:  181\n",
            "HD Size:  191\n",
            "HD Size:  201\n",
            "HD Size:  211\n",
            "HD Size:  221\n",
            "HD Size:  231\n",
            "HD Size:  241\n",
            "HD Size:  251\n",
            "HD Size:  261\n",
            "HD Size:  271\n",
            "HD Size:  281\n",
            "HD Size:  291\n",
            "HD Size:  301\n",
            "HD Size:  311\n",
            "HD Size:  321\n",
            "HD Size:  331\n",
            "HD Size:  341\n",
            "HD Size:  351\n",
            "HD Size:  361\n",
            "HD Size:  371\n",
            "HD Size:  381\n",
            "HD Size:  391\n",
            "HD Size:  401\n",
            "HD Size:  411\n",
            "HD Size:  421\n",
            "HD Size:  431\n",
            "HD Size:  441\n",
            "HD Size:  451\n",
            "HD Size:  461\n",
            "HD Size:  471\n",
            "HD Size:  481\n",
            "HD Size:  491\n",
            "HD Size:  501\n",
            "Dice Size:  1\n",
            "Dice Size:  11\n",
            "Dice Size:  21\n",
            "Dice Size:  31\n",
            "Dice Size:  41\n",
            "Dice Size:  51\n",
            "Dice Size:  61\n",
            "Dice Size:  71\n",
            "Dice Size:  81\n",
            "Dice Size:  91\n",
            "Dice Size:  101\n",
            "Dice Size:  111\n",
            "Dice Size:  121\n",
            "Dice Size:  131\n",
            "Dice Size:  141\n",
            "Dice Size:  151\n",
            "Dice Size:  161\n",
            "Dice Size:  171\n",
            "Dice Size:  181\n",
            "Dice Size:  191\n",
            "Dice Size:  201\n",
            "Dice Size:  211\n",
            "Dice Size:  221\n",
            "Dice Size:  231\n",
            "Dice Size:  241\n",
            "Dice Size:  251\n",
            "Dice Size:  261\n",
            "Dice Size:  271\n",
            "Dice Size:  281\n",
            "Dice Size:  291\n",
            "Dice Size:  301\n",
            "Dice Size:  311\n",
            "Dice Size:  321\n",
            "Dice Size:  331\n",
            "Dice Size:  341\n",
            "Dice Size:  351\n",
            "Dice Size:  361\n",
            "Dice Size:  371\n",
            "Dice Size:  381\n",
            "Dice Size:  391\n",
            "Dice Size:  401\n",
            "Dice Size:  411\n",
            "Dice Size:  421\n",
            "Dice Size:  431\n",
            "Dice Size:  441\n",
            "Dice Size:  451\n",
            "Dice Size:  461\n",
            "Dice Size:  471\n",
            "Dice Size:  481\n",
            "Dice Size:  491\n",
            "Dice Size:  501\n"
          ]
        }
      ],
      "source": [
        "# 3D\n",
        "for array in test_cases_3D:\n",
        "  # HD GPU\n",
        "  print(\"HD Size: \", len(array))\n",
        "  a = []\n",
        "  tfm1 = torch.from_numpy(distance(array)).to(device)\n",
        "  n = len(array)\n",
        "  g = torch.randint(0,2,(n,n,n))\n",
        "  tfm2 = torch.from_numpy(distance(g)).to(device)\n",
        "  array1 = array.to(device)\n",
        "  g1 = g.to(device)\n",
        "  for j in range(1000): #Evaluations\n",
        "    times1 = time.time_ns()\n",
        "    hd = hd_loss_3D(array1, g1, tfm1, tfm2)\n",
        "    times2 = time.time_ns()\n",
        "    a.append(times2-times1)\n",
        "    if sum(a) > (20*60*(10**9)):\n",
        "      break\n",
        "  hd_3D_times.append(a)\n",
        "\n",
        "for array in test_cases_3D:\n",
        "  # Dice GPU\n",
        "  print(\"Dice Size: \",  len(array))\n",
        "  b = []\n",
        "  n = len(array)\n",
        "  g = torch.randint(0,2,(n,n,n)).to(device)\n",
        "  array1 = array.to(device)\n",
        "  for j in range(1000): #Evaluations\n",
        "    times1 = time.time_ns()\n",
        "    dice = dice_loss(array1, g)\n",
        "    times2 = time.time_ns()\n",
        "    b.append(times2-times1)\n",
        "    if sum(b) > (20*60*(10**9)):\n",
        "      break\n",
        "  dice_3D_times.append(b)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0UhJ1tdL0SZ"
      },
      "outputs": [],
      "source": [
        "for i in hd_times:\n",
        "  hd_mean_2D.append(torch.mean(torch.FloatTensor(i)).numpy().tolist())\n",
        "  hd_std_2D.append(torch.std(torch.FloatTensor(i), unbiased = False).numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcQMRi6uNA3h"
      },
      "outputs": [],
      "source": [
        "for i in dice_times:\n",
        "  dice_mean_2D.append(torch.mean(torch.FloatTensor(i)).numpy().tolist())\n",
        "  dice_std_2D.append(torch.std(torch.FloatTensor(i), unbiased = False).numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezT7RYDzWhnE"
      },
      "outputs": [],
      "source": [
        "for i in hd_3D_times:\n",
        "  hd_mean_3D.append(torch.mean(torch.FloatTensor(i)).numpy().tolist())\n",
        "  hd_std_3D.append(torch.std(torch.FloatTensor(i), unbiased = False).numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X9hrQC7Whtc"
      },
      "outputs": [],
      "source": [
        "for i in dice_3D_times:\n",
        "  dice_mean_3D.append(torch.mean(torch.FloatTensor(i)).numpy().tolist())\n",
        "  dice_std_3D.append(torch.std(torch.FloatTensor(i), unbiased = False).numpy().tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6k2_Quvqa68"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qimwNUfNY7sL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKC1D7OlY5hQ"
      },
      "outputs": [],
      "source": [
        "hd_mean = np.array(hd_mean_2D)\n",
        "dice_mean = np.array(dice_mean_2D)\n",
        "hd_3D_mean = np.array(hd_mean_3D)\n",
        "dice_3D_mean = np.array(dice_mean_3D)\n",
        "hd_std = np.array(hd_std_2D)\n",
        "dice_std = np.array(dice_std_2D)\n",
        "hd_3D_std = np.array(hd_std_3D)\n",
        "dice_3D_std = np.array(dice_std_3D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc1c3RM2qpoH"
      },
      "outputs": [],
      "source": [
        "data2D = {'sizes_2D': sizes_2D, 'hd_mean_2D_purePython_GPU': hd_mean, 'dice_mean_2D_purePython_GPU': dice_mean, 'hd_std_2D_purePython_GPU': hd_std, 'dice_std_2D_purePython_GPU': dice_std}\n",
        "data3D = {'sizes_3D': sizes_3D, 'hd_mean_3D_purePython_GPU': hd_3D_mean, 'dice_mean_3D_purePython_GPU': dice_3D_mean, 'hd_std_3D_purePython_GPU': hd_3D_std, 'dice_std_3D_purePython_GPU':dice_3D_std}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ3bkbTsrtZ8"
      },
      "outputs": [],
      "source": [
        "dataframe2D = pd.DataFrame(data2D)\n",
        "dataframe3D = pd.DataFrame(data3D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfQkUZesARW"
      },
      "outputs": [],
      "source": [
        "dataframe2D.to_csv(\"C:/Users/wenbl13/Desktop/Ashwin-Timing/distance-transforms/purePython_Loss_2D_nov9_GPU.csv\")\n",
        "dataframe3D.to_csv(\"C:/Users/wenbl13/Desktop/Ashwin-Timing/distance-transforms/purePython_Loss_3D_nov9_GPU.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "dzspsuWwUPRK",
        "outputId": "d737765c-1344-4e2b-bc8c-939a6d5de78a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sizes_2D</th>\n",
              "      <th>hd_mean_2D_purePython</th>\n",
              "      <th>dice_mean_2D_purePython</th>\n",
              "      <th>hd_std_2D_purePython</th>\n",
              "      <th>dice_std_2D_purePython</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4.419650e+04</td>\n",
              "      <td>6.500280e+04</td>\n",
              "      <td>2.191307e+05</td>\n",
              "      <td>246537.093750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>3.502650e+04</td>\n",
              "      <td>7.447130e+04</td>\n",
              "      <td>1.839436e+05</td>\n",
              "      <td>249019.046875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>3.905360e+04</td>\n",
              "      <td>7.600070e+04</td>\n",
              "      <td>1.938978e+05</td>\n",
              "      <td>265001.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29</td>\n",
              "      <td>4.295990e+04</td>\n",
              "      <td>6.400120e+04</td>\n",
              "      <td>2.027151e+05</td>\n",
              "      <td>244758.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>4.791840e+04</td>\n",
              "      <td>6.204700e+04</td>\n",
              "      <td>2.134462e+05</td>\n",
              "      <td>237418.171875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>49</td>\n",
              "      <td>5.889540e+04</td>\n",
              "      <td>6.108900e+04</td>\n",
              "      <td>2.352520e+05</td>\n",
              "      <td>239535.453125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63</td>\n",
              "      <td>6.998700e+04</td>\n",
              "      <td>6.199280e+04</td>\n",
              "      <td>2.551128e+05</td>\n",
              "      <td>241202.296875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>69</td>\n",
              "      <td>7.192991e+04</td>\n",
              "      <td>6.498600e+04</td>\n",
              "      <td>2.621558e+05</td>\n",
              "      <td>246509.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>83</td>\n",
              "      <td>9.099939e+04</td>\n",
              "      <td>6.702480e+04</td>\n",
              "      <td>2.876398e+05</td>\n",
              "      <td>250190.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>89</td>\n",
              "      <td>9.605101e+04</td>\n",
              "      <td>7.399330e+04</td>\n",
              "      <td>2.947973e+05</td>\n",
              "      <td>261825.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>103</td>\n",
              "      <td>1.182405e+05</td>\n",
              "      <td>7.798770e+04</td>\n",
              "      <td>3.086317e+05</td>\n",
              "      <td>268165.781250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109</td>\n",
              "      <td>1.270770e+05</td>\n",
              "      <td>8.515130e+04</td>\n",
              "      <td>3.139648e+05</td>\n",
              "      <td>277928.968750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>123</td>\n",
              "      <td>1.490518e+05</td>\n",
              "      <td>9.398410e+04</td>\n",
              "      <td>3.562995e+05</td>\n",
              "      <td>291865.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>129</td>\n",
              "      <td>1.640624e+05</td>\n",
              "      <td>1.020232e+05</td>\n",
              "      <td>3.704882e+05</td>\n",
              "      <td>302780.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>143</td>\n",
              "      <td>1.899876e+05</td>\n",
              "      <td>1.090696e+05</td>\n",
              "      <td>3.948590e+05</td>\n",
              "      <td>311901.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>149</td>\n",
              "      <td>2.012076e+05</td>\n",
              "      <td>1.190315e+05</td>\n",
              "      <td>4.000755e+05</td>\n",
              "      <td>323932.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>163</td>\n",
              "      <td>2.289805e+05</td>\n",
              "      <td>1.320270e+05</td>\n",
              "      <td>4.203048e+05</td>\n",
              "      <td>338622.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>169</td>\n",
              "      <td>2.479908e+05</td>\n",
              "      <td>1.380616e+05</td>\n",
              "      <td>4.342157e+05</td>\n",
              "      <td>345120.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>183</td>\n",
              "      <td>2.754253e+05</td>\n",
              "      <td>1.490187e+05</td>\n",
              "      <td>4.453469e+05</td>\n",
              "      <td>356243.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>189</td>\n",
              "      <td>2.479889e+05</td>\n",
              "      <td>1.569663e+05</td>\n",
              "      <td>4.454038e+05</td>\n",
              "      <td>366461.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>203</td>\n",
              "      <td>2.700040e+05</td>\n",
              "      <td>1.769946e+05</td>\n",
              "      <td>4.435537e+05</td>\n",
              "      <td>381657.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>209</td>\n",
              "      <td>3.228779e+05</td>\n",
              "      <td>1.939988e+05</td>\n",
              "      <td>4.627441e+05</td>\n",
              "      <td>395427.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>223</td>\n",
              "      <td>3.329862e+05</td>\n",
              "      <td>2.289332e+05</td>\n",
              "      <td>4.755068e+05</td>\n",
              "      <td>409968.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>229</td>\n",
              "      <td>3.390027e+05</td>\n",
              "      <td>2.412938e+05</td>\n",
              "      <td>4.733757e+05</td>\n",
              "      <td>425510.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>243</td>\n",
              "      <td>3.659746e+05</td>\n",
              "      <td>2.359985e+05</td>\n",
              "      <td>4.837740e+05</td>\n",
              "      <td>429337.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>249</td>\n",
              "      <td>3.879979e+05</td>\n",
              "      <td>2.620019e+05</td>\n",
              "      <td>4.893696e+05</td>\n",
              "      <td>443887.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>263</td>\n",
              "      <td>3.130008e+05</td>\n",
              "      <td>2.330007e+05</td>\n",
              "      <td>4.658810e+05</td>\n",
              "      <td>424672.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>269</td>\n",
              "      <td>3.426477e+05</td>\n",
              "      <td>2.350029e+05</td>\n",
              "      <td>4.670665e+05</td>\n",
              "      <td>426386.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>283</td>\n",
              "      <td>5.872989e+05</td>\n",
              "      <td>2.569924e+05</td>\n",
              "      <td>5.024976e+05</td>\n",
              "      <td>436967.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>289</td>\n",
              "      <td>8.129921e+05</td>\n",
              "      <td>2.609849e+05</td>\n",
              "      <td>4.816825e+05</td>\n",
              "      <td>441428.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>303</td>\n",
              "      <td>4.169877e+05</td>\n",
              "      <td>2.749934e+05</td>\n",
              "      <td>5.031100e+05</td>\n",
              "      <td>450960.781250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>309</td>\n",
              "      <td>1.031310e+06</td>\n",
              "      <td>3.018510e+05</td>\n",
              "      <td>4.207792e+05</td>\n",
              "      <td>455328.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>323</td>\n",
              "      <td>1.192003e+06</td>\n",
              "      <td>2.743266e+05</td>\n",
              "      <td>4.549951e+05</td>\n",
              "      <td>450763.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>329</td>\n",
              "      <td>4.393653e+05</td>\n",
              "      <td>2.730007e+05</td>\n",
              "      <td>4.964775e+05</td>\n",
              "      <td>449957.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>343</td>\n",
              "      <td>9.339212e+05</td>\n",
              "      <td>2.659965e+05</td>\n",
              "      <td>4.350587e+05</td>\n",
              "      <td>444136.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>349</td>\n",
              "      <td>1.792358e+06</td>\n",
              "      <td>2.689908e+05</td>\n",
              "      <td>5.735544e+05</td>\n",
              "      <td>445865.281250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>363</td>\n",
              "      <td>1.716086e+06</td>\n",
              "      <td>2.959989e+05</td>\n",
              "      <td>5.699482e+05</td>\n",
              "      <td>463022.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>369</td>\n",
              "      <td>2.281790e+06</td>\n",
              "      <td>5.929971e+05</td>\n",
              "      <td>6.033161e+05</td>\n",
              "      <td>623969.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>383</td>\n",
              "      <td>2.333658e+06</td>\n",
              "      <td>6.373892e+05</td>\n",
              "      <td>6.321919e+05</td>\n",
              "      <td>690496.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>389</td>\n",
              "      <td>2.600441e+06</td>\n",
              "      <td>6.645322e+05</td>\n",
              "      <td>9.913182e+05</td>\n",
              "      <td>560940.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>403</td>\n",
              "      <td>2.623873e+06</td>\n",
              "      <td>6.649941e+05</td>\n",
              "      <td>8.320362e+05</td>\n",
              "      <td>587208.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>409</td>\n",
              "      <td>2.792188e+06</td>\n",
              "      <td>6.758412e+05</td>\n",
              "      <td>8.772622e+05</td>\n",
              "      <td>558055.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>423</td>\n",
              "      <td>2.858577e+06</td>\n",
              "      <td>7.693112e+05</td>\n",
              "      <td>1.119326e+06</td>\n",
              "      <td>573535.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>429</td>\n",
              "      <td>2.921705e+06</td>\n",
              "      <td>7.570044e+05</td>\n",
              "      <td>1.153156e+06</td>\n",
              "      <td>503890.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>443</td>\n",
              "      <td>3.138452e+06</td>\n",
              "      <td>8.029682e+05</td>\n",
              "      <td>9.089418e+05</td>\n",
              "      <td>627810.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>449</td>\n",
              "      <td>3.271796e+06</td>\n",
              "      <td>7.708701e+05</td>\n",
              "      <td>7.338339e+05</td>\n",
              "      <td>568103.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>463</td>\n",
              "      <td>3.398244e+06</td>\n",
              "      <td>9.170088e+05</td>\n",
              "      <td>1.101134e+06</td>\n",
              "      <td>549644.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>469</td>\n",
              "      <td>3.534167e+06</td>\n",
              "      <td>8.525962e+05</td>\n",
              "      <td>1.125905e+06</td>\n",
              "      <td>603558.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>483</td>\n",
              "      <td>4.011263e+06</td>\n",
              "      <td>8.320096e+05</td>\n",
              "      <td>1.084634e+06</td>\n",
              "      <td>515522.781250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>489</td>\n",
              "      <td>4.177856e+06</td>\n",
              "      <td>9.399929e+05</td>\n",
              "      <td>1.347762e+06</td>\n",
              "      <td>616708.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>503</td>\n",
              "      <td>4.128542e+06</td>\n",
              "      <td>1.106104e+06</td>\n",
              "      <td>9.946592e+05</td>\n",
              "      <td>557597.062500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sizes_2D  hd_mean_2D_purePython  dice_mean_2D_purePython  \\\n",
              "0          3           4.419650e+04             6.500280e+04   \n",
              "1          9           3.502650e+04             7.447130e+04   \n",
              "2         23           3.905360e+04             7.600070e+04   \n",
              "3         29           4.295990e+04             6.400120e+04   \n",
              "4         43           4.791840e+04             6.204700e+04   \n",
              "5         49           5.889540e+04             6.108900e+04   \n",
              "6         63           6.998700e+04             6.199280e+04   \n",
              "7         69           7.192991e+04             6.498600e+04   \n",
              "8         83           9.099939e+04             6.702480e+04   \n",
              "9         89           9.605101e+04             7.399330e+04   \n",
              "10       103           1.182405e+05             7.798770e+04   \n",
              "11       109           1.270770e+05             8.515130e+04   \n",
              "12       123           1.490518e+05             9.398410e+04   \n",
              "13       129           1.640624e+05             1.020232e+05   \n",
              "14       143           1.899876e+05             1.090696e+05   \n",
              "15       149           2.012076e+05             1.190315e+05   \n",
              "16       163           2.289805e+05             1.320270e+05   \n",
              "17       169           2.479908e+05             1.380616e+05   \n",
              "18       183           2.754253e+05             1.490187e+05   \n",
              "19       189           2.479889e+05             1.569663e+05   \n",
              "20       203           2.700040e+05             1.769946e+05   \n",
              "21       209           3.228779e+05             1.939988e+05   \n",
              "22       223           3.329862e+05             2.289332e+05   \n",
              "23       229           3.390027e+05             2.412938e+05   \n",
              "24       243           3.659746e+05             2.359985e+05   \n",
              "25       249           3.879979e+05             2.620019e+05   \n",
              "26       263           3.130008e+05             2.330007e+05   \n",
              "27       269           3.426477e+05             2.350029e+05   \n",
              "28       283           5.872989e+05             2.569924e+05   \n",
              "29       289           8.129921e+05             2.609849e+05   \n",
              "30       303           4.169877e+05             2.749934e+05   \n",
              "31       309           1.031310e+06             3.018510e+05   \n",
              "32       323           1.192003e+06             2.743266e+05   \n",
              "33       329           4.393653e+05             2.730007e+05   \n",
              "34       343           9.339212e+05             2.659965e+05   \n",
              "35       349           1.792358e+06             2.689908e+05   \n",
              "36       363           1.716086e+06             2.959989e+05   \n",
              "37       369           2.281790e+06             5.929971e+05   \n",
              "38       383           2.333658e+06             6.373892e+05   \n",
              "39       389           2.600441e+06             6.645322e+05   \n",
              "40       403           2.623873e+06             6.649941e+05   \n",
              "41       409           2.792188e+06             6.758412e+05   \n",
              "42       423           2.858577e+06             7.693112e+05   \n",
              "43       429           2.921705e+06             7.570044e+05   \n",
              "44       443           3.138452e+06             8.029682e+05   \n",
              "45       449           3.271796e+06             7.708701e+05   \n",
              "46       463           3.398244e+06             9.170088e+05   \n",
              "47       469           3.534167e+06             8.525962e+05   \n",
              "48       483           4.011263e+06             8.320096e+05   \n",
              "49       489           4.177856e+06             9.399929e+05   \n",
              "50       503           4.128542e+06             1.106104e+06   \n",
              "\n",
              "    hd_std_2D_purePython  dice_std_2D_purePython  \n",
              "0           2.191307e+05           246537.093750  \n",
              "1           1.839436e+05           249019.046875  \n",
              "2           1.938978e+05           265001.562500  \n",
              "3           2.027151e+05           244758.734375  \n",
              "4           2.134462e+05           237418.171875  \n",
              "5           2.352520e+05           239535.453125  \n",
              "6           2.551128e+05           241202.296875  \n",
              "7           2.621558e+05           246509.750000  \n",
              "8           2.876398e+05           250190.062500  \n",
              "9           2.947973e+05           261825.000000  \n",
              "10          3.086317e+05           268165.781250  \n",
              "11          3.139648e+05           277928.968750  \n",
              "12          3.562995e+05           291865.593750  \n",
              "13          3.704882e+05           302780.312500  \n",
              "14          3.948590e+05           311901.531250  \n",
              "15          4.000755e+05           323932.437500  \n",
              "16          4.203048e+05           338622.625000  \n",
              "17          4.342157e+05           345120.812500  \n",
              "18          4.453469e+05           356243.875000  \n",
              "19          4.454038e+05           366461.687500  \n",
              "20          4.435537e+05           381657.562500  \n",
              "21          4.627441e+05           395427.000000  \n",
              "22          4.755068e+05           409968.468750  \n",
              "23          4.733757e+05           425510.750000  \n",
              "24          4.837740e+05           429337.437500  \n",
              "25          4.893696e+05           443887.187500  \n",
              "26          4.658810e+05           424672.656250  \n",
              "27          4.670665e+05           426386.375000  \n",
              "28          5.024976e+05           436967.437500  \n",
              "29          4.816825e+05           441428.656250  \n",
              "30          5.031100e+05           450960.781250  \n",
              "31          4.207792e+05           455328.250000  \n",
              "32          4.549951e+05           450763.156250  \n",
              "33          4.964775e+05           449957.875000  \n",
              "34          4.350587e+05           444136.312500  \n",
              "35          5.735544e+05           445865.281250  \n",
              "36          5.699482e+05           463022.656250  \n",
              "37          6.033161e+05           623969.625000  \n",
              "38          6.321919e+05           690496.000000  \n",
              "39          9.913182e+05           560940.312500  \n",
              "40          8.320362e+05           587208.625000  \n",
              "41          8.772622e+05           558055.937500  \n",
              "42          1.119326e+06           573535.875000  \n",
              "43          1.153156e+06           503890.156250  \n",
              "44          9.089418e+05           627810.125000  \n",
              "45          7.338339e+05           568103.062500  \n",
              "46          1.101134e+06           549644.250000  \n",
              "47          1.125905e+06           603558.062500  \n",
              "48          1.084634e+06           515522.781250  \n",
              "49          1.347762e+06           616708.375000  \n",
              "50          9.946592e+05           557597.062500  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi6uQ_QxWyIP"
      },
      "outputs": [],
      "source": [
        "x = [i for i in range(1, 1000, 100)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnqfyU6b1f3r"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "I2XEifHG1sDd",
        "outputId": "54c687ab-7724-4ae4-d90f-819e9e73e46d"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(13, 13))\n",
        "# plt.plot(x, dataframe['hd_mean_2D_purePython'], label = 'hd_mean_2D')\n",
        "# plt.plot(x, dataframe['dice_mean_2D_purePython'], label = 'dice_mean_2D')\n",
        "# plt.plot(x, dataframe['hd_mean_3D_purePython'], label = 'hd_mean_3D')\n",
        "# plt.plot(x, dataframe['dice_mean_3D_purePython'], label = 'dice_mean_3D')\n",
        "# plt.xlabel('Array_Size')\n",
        "# plt.ylabel('Time (seconds)')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIZoA-lU4mwa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "python_loss_functions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d9ef0e181354117f9ce70876735363e58fcc077c1120e406476deb8970979d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
